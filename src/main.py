import asyncio
import logging
import sys

from sqlalchemy import text

from database.models import Base
from database.service import VacancyRepository
from database.sessions import async_session, engine
from scrapers.dou.client import DouScraper


# 1. Ğ¦ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¾Ğ²
def setup_logging(level=logging.INFO):
    log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    logging.basicConfig(level=level, format=log_format, handlers=[logging.StreamHandler(sys.stdout)])
    # Ğ¢Ğ¸Ñ…Ğ¸Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ´Ğ»Ñ ÑˆÑƒĞ¼Ğ½Ñ‹Ñ… Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞº
    logging.getLogger("sqlalchemy.engine").setLevel(logging.WARNING)
    logging.getLogger("curl_cffi").setLevel(logging.WARNING)


logger = logging.getLogger("onigari.main")


async def setup_database():
    """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ±Ğ°Ğ·Ñ‹: Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ñ Ğ¸ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹"""
    try:
        async with engine.begin() as conn:
            await conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))
            logger.info("âœ… PGVector extension is ready")

            # Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•: Ğ² Ğ¿Ñ€Ğ¾Ğ´Ğ°ĞºÑˆĞµĞ½Ğµ Ğ»ÑƒÑ‡ÑˆĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Alembic, Ğ½Ğ¾ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ñ€Ñ‚Ğ° â€” Ğ¾Ğº
            await conn.run_sync(Base.metadata.create_all)
            logger.info("âœ… Database tables verified")
    except Exception as e:
        logger.error(f"âŒ Database setup failed: {e}")
        raise


async def run_scrapers():
    """Ğ¦Ğ¸ĞºĞ» ÑĞ±Ğ¾Ñ€Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²"""
    async with async_session() as session:
        repository = VacancyRepository(session)

        async with DouScraper() as scraper:
            logger.info("ğŸ“¡ Scanning DOU for new opportunities...")
            # ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ±ÑƒĞ´ĞµÑ‚ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¹ Ğ¸Ğ· ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ°
            async for batch in scraper.fetch_vacancies(category="Python"):
                if not batch:
                    continue

                added_count = await repository.batch_upsert(batch)
                if added_count > 0:
                    logger.info(f"ğŸ‘¹ Trapped {added_count} new demons in the database.")


async def main():
    setup_logging()  # Ğ’Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºÑƒ Ğ»Ğ¾Ğ³Ğ¾Ğ² Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼ Ğ´ĞµĞ»Ğ¾Ğ¼
    logger.info("ğŸ‘¹ Project Onigari (é¬¼ç‹©ã‚Š) is waking up...")

    await setup_database()

    while True:
        try:
            logger.info("ğŸš€ Starting new scraping cycle...")
            await run_scrapers()
            logger.info("ğŸ Cycle completed successfully.")
        except Exception as e:
            # exc_info=True Ğ²Ñ‹Ğ²ĞµĞ´ĞµÑ‚ Ğ²ĞµÑÑŒ traceback Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸
            logger.error(f"âš ï¸ Scraper cycle failed: {e}", exc_info=True)

        logger.info("ğŸ’¤ Sleeping for 1 hour before next hunt...")
        await asyncio.sleep(60 * 60)


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ Onigari is going to sleep (KeyboardInterrupt)")
    except Exception as e:
        logger.critical(f"ğŸ’¥ Fatal crash: {e}")
        sys.exit(1)
